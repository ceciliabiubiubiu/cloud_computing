{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as f\nfrom pyspark.sql.types import ArrayType\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.ml.feature import RegexTokenizer\nfrom pyspark.ml.feature import Word2Vec\nimport re", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "35770328f3f64670913f149f2b7c4b57"}}, "metadata": {}}, {"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1558519364302_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-22-34.ap-southeast-2.compute.internal:20888/proxy/application_1558519364302_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-30-156.ap-southeast-2.compute.internal:8042/node/containerlogs/container_1558519364302_0001_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "#STAGE 1\n\n# Create a SparkSession\nspark = SparkSession.builder.appName(\"MusicDataAnalysis\").getOrCreate()\n\n#Load data from S3\nmusic_data = \"s3://amazon-reviews-pds/tsv/amazon_reviews_us_Music_v1_00.tsv.gz\"\nmusics = spark.read.csv(music_data,header=True,sep='\\t')\nmusics = musics.drop('marketplace','product_parent','product_title','product_category','helpful_votes','total_votes','vine','verified_purchase','review_headline','review_date').cache()", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "683a2f7a1a2b49c2a9a0dd867566d59b"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Number of items in the dataset = total count of the reviews\nmusics.count()", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2f09b99116104e23a67999306890e9af"}}, "metadata": {}}, {"output_type": "stream", "text": "4751577", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Count unique customer and product id\nmusics.select(\"customer_id\").distinct().count()", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "986846024c5a44ec87439fe05788bdd7"}}, "metadata": {}}, {"output_type": "stream", "text": "1940732", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "musics.select(\"product_id\").distinct().count()", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0d9f369558c44f6ca9b7fbddb3b8d06c"}}, "metadata": {}}, {"output_type": "stream", "text": "782326", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Largest number of reviews by a single user\nmusics.groupby('customer_id').count().sort(f.col(\"count\"), ascending = False).select(\"count\").limit(1).show()", "execution_count": 6, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "642e2768ef414165ad6ea437a139f5f9"}}, "metadata": {}}, {"output_type": "stream", "text": "+-----+\n|count|\n+-----+\n| 7168|\n+-----+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Top 10 users ranked by reviews\nmusics.groupby('customer_id').count().sort(f.col(\"count\"), ascending = False).select(\"customer_id\").limit(10).show()\n\n#Median number of review for a user\ncount_list_user = musics.groupby('customer_id').count().sort(f.col(\"count\"), ascending = False).select(\"count\").selectExpr(\"count as _count\")\ncount_array_user = [int(row._count) for row in count_list_user.collect()]\nmedian_user = np.median(count_array_user)\nprint(median_user)", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "9702413c3eb6442887d2b8024cd29e96"}}, "metadata": {}}, {"output_type": "stream", "text": "+-----------+\n|customer_id|\n+-----------+\n|   50736950|\n|   38214553|\n|   51184997|\n|   18116317|\n|   23267387|\n|   50345651|\n|   14539589|\n|   15725862|\n|   19380211|\n|   20018062|\n+-----------+\n\n1.0", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Largest number of reviews for a single product\nmusics.groupby('product_id').count().sort(f.col(\"count\"), ascending = False).select(\"count\").limit(1).show()", "execution_count": 8, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6d46910d56174889952794d7e58b91d0"}}, "metadata": {}}, {"output_type": "stream", "text": "+-----+\n|count|\n+-----+\n| 3936|\n+-----+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Top 10 products ranked by reviews\nmusics.groupby('product_id').count().sort(f.col(\"count\"), ascending = False).select(\"product_id\").limit(10).show()\n\n#Median number of review for a product\ncount_list_product = musics.groupby('product_id').count().sort(f.col(\"count\"), ascending = False).select(\"count\").selectExpr(\"count as _count\")\ncount_array_product = [int(row._count) for row in count_list_product.collect()]\nmedian_product = np.median(count_array_product)\nprint(median_product)", "execution_count": 9, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c295e8a9b7f34110a85b27397e33084c"}}, "metadata": {}}, {"output_type": "stream", "text": "+----------+\n|product_id|\n+----------+\n|B00008OWZG|\n|B0000AGWEC|\n|B00MIA0KGY|\n|B00NEJ7MMI|\n|B000089RVX|\n|B004EBT5CU|\n|B0026P3G12|\n|B00009PRZF|\n|B00004XONN|\n|B00006J6VG|\n+----------+\n\n2.0", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#STAGE 2\n\n#split review_body\ndef splitreviews(x):\n    try:\n        if x !=None:\n            x = re.split(\"[.?!]\",x)\n        new_x = []\n        for i in range(len(x)):\n            if x[i] != '':\n                new_x.append(x[i])\n    except:\n        pass\n    return new_x\n#         return x\nfilter_udf = f.udf(lambda y: splitreviews(y), ArrayType(StringType()))\nmusic_f = musics.withColumn(\"review_body\", filter_udf(\"review_body\"))\n# music_f.show()\n\n#Filter length < 2\ngivenlength = 2\nmusic_s = music_f.filter(f.size(music_f.review_body) >= givenlength).cache()\n# music_s.show()\n# music_s.select('review_body').show()", "execution_count": 10, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "9a220e83ea2548f89bb771425c9e7a6e"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Filter by customer id and product id\nc_group = music_s.groupby('customer_id').count().sort(f.col(\"count\"), ascending = False)\nc_group.withColumn(\"count\", c_group[\"count\"].cast(IntegerType()))\nc_group_filter = c_group.filter(f.col(\"count\")> median_user).sort(f.col('count'))\nmusic_filter_c = music_s.join(c_group_filter, [\"customer_id\"], \"leftsemi\")\n\np_group = music_filter_c.groupby('product_id').count().sort(f.col(\"count\"), ascending = False)\np_group.withColumn(\"count\", p_group[\"count\"].cast(IntegerType()))\np_group_filter = p_group.filter(f.col(\"count\")>median_product)\nmusic_filtered = music_filter_c.join(p_group_filter, [\"product_id\"], \"leftsemi\")\n\n#Top 10 users ranked by median number of sentences in the reviews they have published\nmusic_filtered_modified = music_filtered.withColumn('num_sentences', f.size(\"review_body\"))\n# music_filtered_modified.show(5)\nmusic_filtered_modified_user = music_filtered_modified.groupby('customer_id').agg(f.collect_list(\"num_sentences\").alias(\"list_num_sentences\"))\n# music_filtered_modified_user.show(5)\n\ndef find_median(values_list):\n    try:\n        median = np.median(values_list)\n        return int(median)\n    except Exception:\n        return None\n\nmedian_finder = f.udf(find_median, IntegerType())\n\nmusic_filtered_modified_user2 = music_filtered_modified_user.withColumn('median', median_finder(\"list_num_sentences\"))\n# music_filtered_modified3.sort(f.col(\"median\"), ascending = False).limit(10).show()\nmusic_filtered_modified_user2.sort(f.col(\"median\"), ascending = False).select(\"customer_id\").limit(10).show()\n\n# Top 10 products ranked by median number of sentences in the reviews they have received\nmusic_filtered_modified_product = music_filtered_modified.groupby('product_id').agg(f.collect_list(\"num_sentences\").alias(\"list_num_sentences\"))\n# music_filtered_modified_product.show(5)\nmusic_filtered_modified_product2 = music_filtered_modified_product.withColumn('median', median_finder(\"list_num_sentences\"))\n# music_filtered_modified_product2.sort(f.col(\"median\"), ascending = False).limit(10).show()\nmusic_filtered_modified_product2.sort(f.col(\"median\"), ascending = False).select(\"product_id\").limit(10).show()", "execution_count": 11, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a40fd8b31252404c991b8fc1949c94ec"}}, "metadata": {}}, {"output_type": "stream", "text": "+-----------+\n|customer_id|\n+-----------+\n|   40611822|\n|   25628286|\n|   51865782|\n|   37118941|\n|   50595705|\n|   23717536|\n|   43879820|\n|   17821650|\n|   46097534|\n|   37733322|\n+-----------+\n\n+----------+\n|product_id|\n+----------+\n|B00061NSU2|\n|B003Z4Y5HW|\n|B007USIWPU|\n|B0000A2ZV8|\n|B000000SI5|\n|B00T5GY470|\n|B00O1BC2FU|\n|B00PA9A1AU|\n|B00386FG0M|\n|B005SGZBHI|\n+----------+\n\n----------------------------------------\nException happened during processing of request from ('127.0.0.1', 46514)\nTraceback (most recent call last):\n  File \"/usr/lib64/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n    self.process_request(request, client_address)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 351, in process_request\n    self.finish_request(request, client_address)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 364, in finish_request\n    self.RequestHandlerClass(request, client_address, self)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 724, in __init__\n    self.handle()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 266, in handle\n    poll(authenticate_and_accum_updates)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 241, in poll\n    if func():\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 254, in authenticate_and_accum_updates\n    received_token = self.rfile.read(len(auth_token))\nTypeError: object of type 'NoneType' has no len()\n----------------------------------------", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#STAGE 3\n\n#Choose product ID and create two class dataframe\nmusic_product = music_filtered.filter(f.col('product_id') == 'B00006J6VG').drop('product_id','customer_id')\nmusic_positive = music_product.filter(f.col('star_rating') > 3).cache()\nmusic_negative = music_product.filter(f.col('star_rating') < 3).cache()\nmusic_positive = music_positive.drop('star_rating')\nmusic_negative = music_negative.drop('star_rating')\n# music_positive.show()\n\n#create rdd for two class\nmusic_p_small = music_positive.limit(music_positive.count())\nmusic_p_small_rdd = music_p_small.rdd.cache()\nmusic_n_small = music_negative.limit(music_negative.count())\nmusic_n_small_rdd = music_n_small.rdd.cache()", "execution_count": 12, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "9bba3a2a68eb4d33b607e9b537a3ff64"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#encode function\ndef review_encode(x):\n \n    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n    embed = hub.Module(module_url)\n    review_list = []\n    review_number = []\n    result_list = []\n\n    temp_x = [t for t in x]\n\n    for i in temp_x:\n        rid = i[0]\n        r_body = i[1]\n#         review_number.append(len(r_body))\n        review_list += r_body\n        result_list.append(i)\n\n    with tf.Session() as session:\n        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n        embeddings = session.run(embed(review_list))\n\n    \n    final_result = []\n    n = 0\n    for l in result_list:\n        rid = l[0]\n        r_body = l[1]\n        for i in r_body:\n#         for vec in embeddings:\n            vec_list = [rid, i, embeddings[n]]\n            final_result.append(vec_list)\n            n+=1\n            \n    return final_result\n#     return embeddings\n\n#encode for two class\nreview_embedding_p_s3 = music_p_small_rdd.mapPartitions(review_encode).cache()\n# review_embedding_p_s3.count()\nreview_embedding_n_s3 = music_n_small_rdd.mapPartitions(review_encode).cache()\n# review_embedding_n_s3.count()\n", "execution_count": 13, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4772d831db93483bb2989ceebd88a097"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#create numpy array for all vectors\ndef return_list(x):\n    vec_list = []\n    for i in x:\n        vec = i[2]\n        vec_list.append(vec)\n    return vec_list\n#positive array\nvec_list_p_s3 = review_embedding_p_s3.mapPartitions(return_list).cache()\n# vec_list_p_s3.count()\nvec_array_p_s3 = np.array(vec_list_p_s3.collect())\n# print(vec_array_p_s3.shape)\n#negative array\nvec_list_n_s3 = review_embedding_n_s3.mapPartitions(return_list).cache()\n# vec_list_n_s3.count()\nvec_array_n_s3 = np.array(vec_list_n_s3.collect())\n# print(vec_array_n_s3.shape)", "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ae58aacd9b9c480abb34f30f4bc13b87"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#caculate positive average distance \ndef calculate_p_s3_distance(x):\n#     temp_x = [t for t in x]\n    dis = []\n    dis_mean = []\n    v1 = x\n    for v in vec_array_p_s3:\n        dot_value = 1 - float((np.dot(v1, v)) / (np.linalg.norm(v1)*np.linalg.norm(v)))\n        dis.append(dot_value)\n\n    a = np.mean(dis)\n    dis_mean.append(a)\n    return dis_mean\n\n#caculate negative average distance\ndef calculate_n_s3_distance(x):\n#     temp_x = [t for t in x]\n    dis = []\n    dis_mean = []\n    v1 = x\n    for v in vec_array_n_s3:\n        dot_value = 1 - float((np.dot(v1, v)) / (np.linalg.norm(v1)*np.linalg.norm(v)))\n        dis.append(dot_value)\n\n    a = np.mean(dis)\n    dis_mean.append(a)\n    return dis_mean\n\n#positive average distance\naverage_distance_p_s3 = vec_list_p_s3.map(calculate_p_s3_distance).cache()\n# average_distance_p_s3.take(1)\n\n#negative average distance\naverage_distance_n_s3 = vec_list_n_s3.map(calculate_n_s3_distance).cache()\n# average_distance_n_s3.take(1)\n\n#zip two rdd: (review_id, review_sentence, vector, average_distance)\n#positive zip\nzip_rdd_p_s3 = review_embedding_p_s3.zip(average_distance_p_s3).map(lambda x: (x[0][0],x[0][1],x[0][2],x[1][0]))\n# zip_rdd_p_s3.take(5)\n#negative zip\nzip_rdd_n_s3 = review_embedding_n_s3.zip(average_distance_n_s3).map(lambda x: (x[0][0],x[0][1],x[0][2],x[1][0]))\n# zip_rdd_n_s3.take(5)", "execution_count": 15, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d96ea52176844d7ea19faccef08bde9d"}}, "metadata": {}}]}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "#sort and find center vector\n#positive class center\nzip_sort_p_s3 = zip_rdd_p_s3.sortBy(lambda x: x[-1])\np_center_list_s3 = zip_sort_p_s3.take(1)\np_center_s3 = (p_center_list_s3[0][0],p_center_list_s3[0][1])\np_center_vec_s3 = p_center_list_s3[0][2]\nprint(p_center_s3)\nprint(\"-----------------\")\n#negative class center\nzip_sort_n_s3 = zip_rdd_n_s3.sortBy(lambda x: x[-1])\nn_center_list_s3 = zip_sort_n_s3.take(1)\nn_center_s3 = (n_center_list_s3[0][0],n_center_list_s3[0][1])\nn_center_vec_s3 = n_center_list_s3[0][2]\nprint(n_center_s3)", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "71655365943148d68faadef415f76f3a"}}, "metadata": {}}, {"output_type": "stream", "text": "('R1YEXVPMKYXOVC', ' just an awesome song')\n-----------------\n('R2L4PZC7CHGQ4R', ' This album is much too insipid for people who like to listen to real music')", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#find positive nearest 10 vector\ndef neareast_p_s3_10(x):\n    v = x[2]\n    rid = x[0]\n    dis = []\n    dot_value = 1 - float((np.dot(p_center_vec_s3, v)) / (np.linalg.norm(p_center_vec_s3)*np.linalg.norm(v)))\n\n    return (rid, dot_value)\n\n#positive neareast 10\nid_dis_p_s3 = review_embedding_p_s3.map(neareast_p_s3_10)\nnear_10_p_s3 = id_dis_p_s3.sortBy(lambda x: x[1])\nnear_10_p_s3_list = near_10_p_s3.take(11)\nnear_10_p_s3_list = near_10_p_s3_list[1::]\nfor i in near_10_p_s3_list:\n    print(i[0])\n\nprint(\"-----------------\")\n\n#find negative nearest 10 vector\ndef neareast_n_s3_10(x):\n    v = x[2]\n    rid = x[0]\n    dis = []\n    dot_value = 1 - float((np.dot(n_center_vec_s3, v)) / (np.linalg.norm(n_center_vec_s3)*np.linalg.norm(v)))\n\n    return (rid, dot_value)\n\n\n    \n#negative neareast 10\nid_dis_n_s3 = review_embedding_n_s3.map(neareast_n_s3_10)\nnear_10_n_s3 = id_dis_n_s3.sortBy(lambda x: x[1])\nnear_10_n_s3_list = near_10_n_s3.take(11)\nnear_10_n_s3_list = near_10_n_s3_list[1::]\nfor i in near_10_n_s3_list:\n    print(i[0])", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "7f2defda5630427f940346cd85a98891"}}, "metadata": {}}, {"output_type": "stream", "text": "R3OSCPFNN3SAAS\nR2EKY5I5KJW2PB\nR2H1YNHUCT31TS\nRY3PCDQ80U0O8\nR3OSCPFNN3SAAS\nR2RZANPP1RFQ7M\nR1BMO598TXFB7R\nR1W2RU1V7J3IGI\nR2RZANPP1RFQ7M\nRM2Z9V7TKMH7P\n-----------------\nR36BAXRVCR2PFB\nR2UBEJ5JX4PKX1\nR195DYX83KWYXU\nR3QG1GKJO8IL4K\nR1DP63VJ4NXY44\nR1DP63VJ4NXY44\nR1CA8OIEZ0B22Y\nRKN17VFTZQ69P\nRATB9UCW9ZV0B\nRKEOBZVEWY7RW", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#STAGE 4\n\n#preprocess function before encode\ndef review_encode_preprocess(x):\n    review_list = []\n    result_list = []\n    temp_x = [t for t in x]\n    for i in temp_x:\n        rid = i[0]\n        r_body = i[1]\n        review_list += r_body\n        result_list.append(i)\n\n    final_result = []\n    for l in result_list:\n        rid = l[0]\n        r_body = l[1]\n        for i in r_body:\n            if(i != \" \"):\n                reformat_list = [rid, i]\n                final_result.append(reformat_list)\n    return final_result\n\n#Preprocess the rdd from stage 3 for both positive and negative\nmusic_p_small_preprocess = music_p_small_rdd.mapPartitions(review_encode_preprocess).cache()\n# music_p_small_preprocess.take(2)\nmusic_n_small_preprocess = music_n_small_rdd.mapPartitions(review_encode_preprocess).cache()\n# music_n_small_preprocess.take(2)\n\n#Re-formate the preprocessed rdd to formatted dataframe\nmusic_p_preprocess_reformat = spark.createDataFrame(music_p_small_preprocess)\nmusic_p_preprocess_reformat = music_p_preprocess_reformat.withColumnRenamed('_1', 'review_id').withColumnRenamed('_2', 'review_body')\nmusic_p_preprocess_reformat = music_p_preprocess_reformat.withColumn('review_body', f.ltrim(music_p_preprocess_reformat.review_body))\nmusic_p_preprocess_reformat = music_p_preprocess_reformat.withColumn('review_body', f.rtrim(music_p_preprocess_reformat.review_body))\n# music_p_preprocess_reformat.show(5)\nmusic_n_preprocess_reformat = spark.createDataFrame(music_n_small_preprocess)\nmusic_n_preprocess_reformat = music_n_preprocess_reformat.withColumnRenamed('_1', 'review_id').withColumnRenamed('_2', 'review_body')\nmusic_n_preprocess_reformat = music_n_preprocess_reformat.withColumn('review_body', f.ltrim(music_n_preprocess_reformat.review_body))\nmusic_n_preprocess_reformat = music_n_preprocess_reformat.withColumn('review_body', f.rtrim(music_n_preprocess_reformat.review_body))\n# music_n_preprocess_reformat.show(5)\n\n#Doing tokenizer with regex to separate every word in review body and filter if empty list\nregexTokenizer = RegexTokenizer(gaps = False, pattern = '\\w+', inputCol = 'review_body', outputCol = 'review_token')\nmusic_p_preprocess_reformat_token = regexTokenizer.transform(music_p_preprocess_reformat)\nmusic_p_preprocess_reformat_token_filter = music_p_preprocess_reformat_token.filter(f.size('review_token') > 1)\n# music_p_preprocess_reformat_token_filter.show(5)\nmusic_n_preprocess_reformat_token = regexTokenizer.transform(music_n_preprocess_reformat)\nmusic_n_preprocess_reformat_token_filter = music_n_preprocess_reformat_token.filter(f.size('review_token') > 1)\n# music_n_preprocess_reformat_token_filter.show(5)\n\n#Create an average word vector for each sentence\nword2vec = Word2Vec(vectorSize = 512, minCount = 1, inputCol = 'review_token', outputCol = 'vector')\nmodel_p = word2vec.fit(music_p_preprocess_reformat_token_filter)\nresult_p = model_p.transform(music_p_preprocess_reformat_token_filter)\n# result_p.count()\n# result_p.show(5)\nmodel_n = word2vec.fit(music_n_preprocess_reformat_token_filter)\nresult_n = model_n.transform(music_n_preprocess_reformat_token_filter)\n\n#Drop the unwanted column and transfer to rdd type\nresult_p = result_p.drop('review_token')\nresult_p_rdd = result_p.rdd\nresult_n = result_n.drop('review_token')\nresult_n_rdd = result_n.rdd", "execution_count": 18, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "606b3bf2f59d4e6a9580f4603743c4e4"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#reformat function after encode\ndef rdd_reformat(x):\n    final_result = []\n    for l in x:\n        rid = l[0]\n        r_body = l[1]\n        r_vec = l[2].toArray().astype(np.double)\n        reformat_list = [rid, r_body, r_vec]\n        final_result.append(reformat_list)\n    return final_result\n\n#Re-format the rdd to review_id, review_body, vector\nresult_p_rdd_reformat = result_p_rdd.mapPartitions(rdd_reformat).cache()\n# result_p_rdd_reformat.count()\n# result_p_rdd_reformat.take(2)\nresult_n_rdd_reformat = result_n_rdd.mapPartitions(rdd_reformat).cache()\n# result_n_rdd_reformat.count()\n# result_n_rdd_reformat.take(2)\n\n#create numpy array for all vectors\ndef np_array_vectors(x):\n    vec_list = []\n    for i in x:\n        vec = i[2]\n        vec_list.append(vec)\n    return vec_list\n\n#positive array\nresult_p_vec_list = result_p_rdd_reformat.mapPartitions(np_array_vectors).cache()\nresult_p_vec_array = np.array(result_p_vec_list.collect())\n# print(result_p_vec_array.shape)\n# result_p_vec_array[0]\n#negative array\nresult_n_vec_list = result_n_rdd_reformat.mapPartitions(np_array_vectors).cache()\nresult_n_vec_array = np.array(result_n_vec_list.collect())\n# print(result_n_vec_array.shape)\n# result_n_vec_array[0]\n\n#caculate positive average distance\ndef calculate_p_w2v_distance(x):\n    dis = []\n    dis_mean = []\n    v1 = x\n    for v in result_p_vec_array:\n        dot_value = 1 - float((np.dot(v1, v)) / (np.linalg.norm(v1)*np.linalg.norm(v)))\n        dis.append(dot_value)\n\n    a = np.mean(dis)\n    dis_mean.append(a)\n    return dis_mean\n\n#caculate negative average distance\ndef calculate_n_w2v_distance(x):\n    dis = []\n    dis_mean = []\n    v1 = x\n    for v in result_n_vec_array:\n        dot_value = 1 - float((np.dot(v1, v)) / (np.linalg.norm(v1)*np.linalg.norm(v)))\n        dis.append(dot_value)\n\n    a = np.mean(dis)\n    dis_mean.append(a)\n    return dis_mean\n\n#positive average distance (take longer time)\naverage_distance_p_w2v = result_p_vec_list.map(calculate_p_w2v_distance).cache()\n# average_distance_p_w2v.take(5)\n#negative average distance (take longer time)\naverage_distance_n_w2v = result_n_vec_list.map(calculate_n_w2v_distance).cache()\n# average_distance_n_w2v.take(5)\n\n#zip two rdd: (review_id, review_sentence, vector, average_distance)\n#positive zip\nzip_rdd_p_w2v = result_p_rdd_reformat.zip(average_distance_p_w2v).map(lambda x: (x[0][0],x[0][1],x[0][2],x[1][0]))\n# zip_rdd_p_w2v.take(5)\n#negative zip\nzip_rdd_n_w2v = result_n_rdd_reformat.zip(average_distance_n_w2v).map(lambda x: (x[0][0],x[0][1],x[0][2],x[1][0]))\n# zip_rdd_n_w2v.take(5)\n\n#sort and find center vector\n#positive class center\nzip_sort_p_w2v = zip_rdd_p_w2v.sortBy(lambda x: x[-1])\np_center_list_w2v = zip_sort_p_w2v.take(1)\np_center_w2v = (p_center_list_w2v[0][0], p_center_list_w2v[0][1])\np_center_vec_w2v = p_center_list_w2v[0][2]\nprint(p_center_w2v)\nprint(\"-----------------\")\n#negative class center\nzip_sort_n_w2v = zip_rdd_n_w2v.sortBy(lambda x: x[-1])\nn_center_list_w2v = zip_sort_n_w2v.take(1)\nn_center_w2v = (n_center_list_w2v[0][0], n_center_list_w2v[0][1])\nn_center_vec_w2v = n_center_list_w2v[0][2]\nprint(n_center_w2v)", "execution_count": 19, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "385e7988157b4ac0a4723c738f54f0df"}}, "metadata": {}}, {"output_type": "stream", "text": "('R2JHEVBBH3TIJZ', 'Bloody Valentine has to be about the best song on the cd, even though its about killing someone its an awesome song  and ive come to this conclusion because so many people i know have told me how much they love it')\n-----------------\n('RV9TLI1TKAOYP', 'They have made the average high school idiot think that being punk is about your clothes and how many peircings you have, and again I can understand why punks want to go Columbine on the preppy people who think Good Charlotte is rated in the same class as Anti Flag or The Misfits')", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#find positive nearest 10 vector\ndef neareast_p_w2v_10(x):\n    v = x[2]\n    rid = x[0]\n    dot_value = 1 - float((np.dot(p_center_vec_w2v, v)) / (np.linalg.norm(p_center_vec_w2v)*np.linalg.norm(v)))\n    return (rid, dot_value)\n\n#positive neareast 10\nid_dis_p_w2v = result_p_rdd_reformat.map(neareast_p_w2v_10)\nnear_10_p_w2v = id_dis_p_w2v.sortBy(lambda x: x[1])\nnear_10_p_w2v_list = near_10_p_w2v.take(11)\nnear_10_p_w2v_list = near_10_p_w2v_list[1::]\nfor i in near_10_p_w2v_list:\n    print(i[0])\n\nprint(\"-----------------\")\n\n#find negative nearest 10 vector\ndef neareast_n_w2v_10(x):\n    v = x[2]\n    rid = x[0]\n    dot_value = 1 - float((np.dot(n_center_vec_w2v, v)) / (np.linalg.norm(n_center_vec_w2v)*np.linalg.norm(v)))\n    return (rid, dot_value)\n\n#negative neareast 10\nid_dis_n_w2v = result_n_rdd_reformat.map(neareast_n_w2v_10)\nnear_10_n_w2v = id_dis_n_w2v.sortBy(lambda x: x[1])\nnear_10_n_w2v_list = near_10_n_w2v.take(11)\nnear_10_n_w2v_list = near_10_n_w2v_list[1::]\nfor i in near_10_n_w2v_list:\n    print(i[0])", "execution_count": 20, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c56a1441a4644201abd1e83192355b63"}}, "metadata": {}}, {"output_type": "stream", "text": "R11K39GJQIHVM7\nR1HWMPUYUW9KMT\nRY3PCDQ80U0O8\nR36KVYD91K4JDD\nR2TWK4QDP00KYK\nRWHWS0A2IKWLB\nRK9SGITJHUAEX\nR1ZXWNL7DIQNK4\nR2K78UJNJE4RKO\nR22CD2HMRRLJ7L\n-----------------\nRBPUHIYNI8FF9\nR2KFKTCQFRJI05\nR302XPK0GQ0VWP\nR2E3X3CIMYF5JT\nRV9TLI1TKAOYP\nR4JQMJ7S6K92X\nR1E4HC0RBS6O2Q\nR3MGK1ZXH61TIS\nR24DPPKVHC5Q7G\nRTWYBI9VBUZCY", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}